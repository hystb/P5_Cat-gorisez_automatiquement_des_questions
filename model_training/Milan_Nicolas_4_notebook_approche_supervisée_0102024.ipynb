{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import jaccard_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import time\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('X_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  score  \\\n",
      "0           0  How can I use optional chaining with arrays an...    321   \n",
      "1           1  What is the use of PYTHONUNBUFFERED in docker ...    308   \n",
      "2           2  IntelliJ: Error:java: error: release version 5...    282   \n",
      "3           3    Maven dependencies are failing with a 501 error    220   \n",
      "4           4  react-testing-library: some portion of debug&#...    205   \n",
      "\n",
      "                                                tags        creation_date  \\\n",
      "0  javascript,arrays,typescript,function,optional...  2020-01-07T08:05:02   \n",
      "1                           django,docker,dockerfile  2020-01-19T17:23:11   \n",
      "2                                 java,intellij-idea  2020-01-05T15:54:15   \n",
      "3                   java,maven,jenkins,maven-central  2020-01-16T06:31:52   \n",
      "4    javascript,reactjs,jestjs,react-testing-library  2020-01-16T06:54:02   \n",
      "\n",
      "   is_english                       cleaned_title  \\\n",
      "0        True  optional chaining arrays functions   \n",
      "1        True                         docker file   \n",
      "2        True  intellij release version supported   \n",
      "3        True          maven dependencies failing   \n",
      "4        True  reacttestinglibrary output visible   \n",
      "\n",
      "          cleaned_title_strict                                  lm  \n",
      "0            optional chaining    optional chaining array function  \n",
      "1                       docker                         docker file  \n",
      "2                     intellij  intellij release version supported  \n",
      "3                        maven            maven dependency failing  \n",
      "4  reacttestinglibrary visible  reacttestinglibrary output visible  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = df['tags'].apply(lambda x: x.split(','))\n",
    "tag_counter = Counter([tag for tags in y_raw for tag in tags])\n",
    "most_common_tags = [tag for tag, _ in tag_counter.most_common(100)]\n",
    "df['filtered_tags'] = y_raw.apply(lambda tags: [tag for tag in tags if tag in most_common_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55813, 10)\n",
      "(50633, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.dropna(subset=['filtered_tags'], inplace=True)\n",
    "data = df[df['filtered_tags'].apply(len) > 0]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned_title']\n",
    "y_raw = data['filtered_tags']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y_raw)\n",
    "tag_distribution = y.sum(axis=0)\n",
    "constant_tags = tag_distribution == len(y)\n",
    "y = y[:, ~constant_tags]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def bow(self):\n",
    "        vectorizer_bow = CountVectorizer()\n",
    "        self.X_train_bow = vectorizer_bow.fit_transform(self.X_train)\n",
    "        self.X_test_bow = vectorizer_bow.transform(self.X_test)\n",
    "        \n",
    "    def w2v(self):\n",
    "        tokenized_corpus = [text.split() for text in self.X_train]\n",
    "        w2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        self.X_train_w2v = np.array([np.mean([w2v_model.wv[word] for word in sentence.split() if word in w2v_model.wv] \\\n",
    "                                or [np.zeros(100)], axis=0) for sentence in self.X_train])\n",
    "        self.X_test_w2v = np.array([np.mean([w2v_model.wv[word] for word in sentence.split() if word in w2v_model.wv] \\\n",
    "                               or [np.zeros(100)], axis=0) for sentence in self.X_test])\n",
    "    \n",
    "    def bert(self, batch_size=20480):\n",
    "        def encode(texts):\n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            model = BertModel.from_pretrained('bert-base-uncased')\n",
    "            all_embeddings = []\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "                with torch.no_grad(): \n",
    "                    outputs = model(**inputs)\n",
    "                embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "                all_embeddings.append(embeddings)\n",
    "            return np.vstack(all_embeddings)\n",
    "        self.X_train_bert = encode(self.X_train)\n",
    "        self.X_test_bert = encode(self.X_test)\n",
    "    \n",
    "    def use(self):\n",
    "        def encode(texts):\n",
    "            model = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "            return model(texts).numpy()\n",
    "        self.X_train_use = encode(self.X_train)\n",
    "        self.X_test_use = encode(self.X_test)\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        self.X_train = self.X_train.fillna('').astype(str).tolist()\n",
    "        self.X_test = self.X_test.fillna('').astype(str).tolist()\n",
    "    \n",
    "    def transform(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.X_train = X_train\n",
    "        self.y_test = y_test\n",
    "        self.handle_missing_values()\n",
    "        self.bow()\n",
    "        self.w2v()\n",
    "        self.bert()\n",
    "        self.use()\n",
    "        data = {\n",
    "            'bow': (self.X_train_bow, self.X_test_bow),\n",
    "            'w2v': (self.X_train_w2v, self.X_test_w2v),\n",
    "            'bert': (self.X_train_bert, self.X_test_bert),\n",
    "            'use': (self.X_train_use, self.X_test_use)\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = FeatureExtractor().transform(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, data):\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.X_train = X_train\n",
    "        self.y_test = y_test\n",
    "        self.data = data\n",
    "    \n",
    "    def precision_at_n(self, y_true, y_pred, n=10):\n",
    "        \"\"\"Calculate precision at N.\"\"\"\n",
    "        precisions = []\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            # True positive count in top N\n",
    "            true_positives = np.sum(np.isin(np.where(true == 1)[0], np.where(pred == 1)[0]))\n",
    "            precisions.append(true_positives / min(n, np.sum(pred)))\n",
    "        return np.mean(precisions)\n",
    "\n",
    "    def recall_at_n(self, y_true, y_pred, n=10):\n",
    "        \"\"\"Calculate recall at N.\"\"\"\n",
    "        recalls = []\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            # True positive count in top N\n",
    "            true_positives = np.sum(np.isin(np.where(true == 1)[0], np.where(pred == 1)[0]))\n",
    "            recalls.append(true_positives / np.sum(true))\n",
    "        return np.mean(recalls)\n",
    "       \n",
    "    def train_and_evaluate(self, X_train, X_test, y_train, y_test, model, model_name, vectorizer_name, n_tag=10):\n",
    "        start_time = time.time()\n",
    "        clf = OneVsRestClassifier(model)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        training_duration = time.time() - start_time\n",
    "        prediction_start_time = time.time()\n",
    "        y_pred_proba = clf.predict_proba(X_test)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_top_n = np.argsort(-y_pred_proba, axis=1)[:, :n_tag]\n",
    "        y_n = np.zeros_like(y_pred_proba)\n",
    "        for i in range(y_pred_top_n.shape[0]):\n",
    "            y_n[i, y_pred_top_n[i]] = 1\n",
    "            \n",
    "        prediction_duration = time.time() - prediction_start_time\n",
    "\n",
    "        precision = self.precision_at_n(y_test, y_n, n=n_tag)\n",
    "        recall = self.recall_at_n(y_test, y_n, n=n_tag)\n",
    "        score = jaccard_score(y_test, y_pred, average='samples')\n",
    "        print(f'Jaccard Score ({vectorizer_name} + {model_name}): {score}')\n",
    "        \n",
    "        print(f'Precision@{n_tag} ({vectorizer_name} + {model_name}): {precision}')\n",
    "        print(f'Recall@{n_tag} ({vectorizer_name} + {model_name}): {recall}')\n",
    "        \n",
    "        input_example = X_train[:1]\n",
    "        signature = infer_signature(X_train, clf.predict(X_train))\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param(\"vectorizer\", vectorizer_name)\n",
    "            mlflow.log_param(\"model\", model_name)\n",
    "            mlflow.log_metric(f\"precision_at_{n_tag}\", precision)\n",
    "            mlflow.log_metric(f\"recall_at_{n_tag}\", recall)\n",
    "            mlflow.log_metric(\"jaccard_score\", score)\n",
    "            mlflow.log_metric(\"training_duration\", training_duration)\n",
    "            mlflow.log_metric(\"prediction_duration\", prediction_duration)\n",
    "            mlflow.sklearn.log_model(clf, \"model\", signature=signature, input_example=input_example)\n",
    "\n",
    "        return clf, X_test, y_pred\n",
    "\n",
    "    def plot_pca_tsne(self, X, y_pred, vectorizer_name, method='PCA'):\n",
    "        \"\"\"\n",
    "        Visualize the results using PCA or t-SNE.\n",
    "        \"\"\"\n",
    "        if method == 'PCA':\n",
    "            if hasattr(X, 'todense'):\n",
    "                reducer = TruncatedSVD(n_components=2)\n",
    "            else:\n",
    "                reducer = PCA(n_components=2)\n",
    "            title = f'PCA Visualization ({vectorizer_name})'\n",
    "        elif method == 't-SNE':\n",
    "            if hasattr(X, 'todense'):\n",
    "                 X = np.asarray(X.todense())\n",
    "            reducer = TSNE(n_components=2, random_state=42)\n",
    "            title = f't-SNE Visualization ({vectorizer_name})'\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'PCA' or 't-SNE'\")\n",
    "        \n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "        \n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y_pred.argmax(axis=1), cmap='viridis', s=10)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(f\"{method} Component 1\")\n",
    "        plt.ylabel(f\"{method} Component 2\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "            \n",
    "    def run(self, models):\n",
    "        for model_name, model in models.items():\n",
    "            for vectorizer_name, (X_train, X_test) in self.data.items():\n",
    "                clf, X_test, y_pred = self.train_and_evaluate(X_train, X_test, self.y_train, self.y_test, model, model_name, vectorizer_name)\n",
    "                self.plot_pca_tsne(X_test, y_pred, vectorizer_name, method='PCA')\n",
    "                self.plot_pca_tsne(X_test, y_pred, vectorizer_name, method='t-SNE')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train, y_train, X_test, y_test, data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Score (bow + SGD Classifier): 0.459744577202857\n",
      "Precision@10 (bow + SGD Classifier): 0.1458181100029624\n",
      "Recall@10 (bow + SGD Classifier): 0.8362446924064382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: CalibratedClassifierCV(SGDClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultinomialNB\u001b[39m\u001b[38;5;124m\"\u001b[39m: MultinomialNB(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;66;03m#\"SVM\": SVC(probability=True),\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         }\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 97\u001b[0m, in \u001b[0;36mModel.run\u001b[1;34m(self, models)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m vectorizer_name, (X_train, X_test) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 97\u001b[0m         clf, X_test, y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_pca_tsne(X_test, y_pred, vectorizer_name, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_pca_tsne(X_test, y_pred, vectorizer_name, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt-SNE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 62\u001b[0m, in \u001b[0;36mModel.train_and_evaluate\u001b[1;34m(self, X_train, X_test, y_train, y_test, model, model_name, vectorizer_name, n_tag)\u001b[0m\n\u001b[0;32m     60\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, training_duration)\n\u001b[0;32m     61\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction_duration)\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clf, X_test, y_pred\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:412\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m    335\u001b[0m     sk_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    348\u001b[0m ):\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    containing the following flavors:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m \n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\models\\model.py:725\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    722\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    723\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[0;32m    724\u001b[0m )\n\u001b[1;32m--> 725\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:304\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    301\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m get_default_pip_requirements(include_cloudpickle)\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     inferred_reqs \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pip_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFLAVOR_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(inferred_reqs)\u001b[38;5;241m.\u001b[39munion(default_reqs))\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\utils\\environment.py:417\u001b[0m, in \u001b[0;36minfer_pip_requirements\u001b[1;34m(model_uri, flavor, fallback, timeout)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _infer_requirements(model_uri, flavor, raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error)\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error \u001b[38;5;129;01mor\u001b[39;00m (fallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:502\u001b[0m, in \u001b[0;36m_infer_requirements\u001b[1;34m(model_uri, flavor, raise_on_error)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _PYPI_PACKAGE_INDEX \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     _PYPI_PACKAGE_INDEX \u001b[38;5;241m=\u001b[39m _load_pypi_package_index()\n\u001b[1;32m--> 502\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43m_capture_imported_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m packages \u001b[38;5;241m=\u001b[39m _flatten([_MODULES_TO_PACKAGES\u001b[38;5;241m.\u001b[39mget(module, []) \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules])\n\u001b[0;32m    504\u001b[0m packages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(_normalize_package_name, packages)\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:379\u001b[0m, in \u001b[0;36m_capture_imported_modules\u001b[1;34m(model_uri, flavor, record_full_module)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _capture_modules\n\u001b[0;32m    378\u001b[0m error_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmpdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 379\u001b[0m \u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_capture_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--flavor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--output-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--error-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--sys-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrecord_full_module_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmain_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_MLFLOW_IN_CAPTURE_MODULE_PROCESS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(error_file):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(error_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\milan\\Documents\\oc\\.oc\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:252\u001b[0m, in \u001b[0;36m_run_command\u001b[1;34m(cmd, timeout_seconds, env)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 252\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m     stderr \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = {\n",
    "            \"SGD Classifier\": CalibratedClassifierCV(SGDClassifier(random_state=42, n_jobs=10), method='sigmoid', cv=5),\n",
    "            \"MultinomialNB\": MultinomialNB(),\n",
    "            # \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=10),\n",
    "            # \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42, n_jobs=10),\n",
    "            #\"SVM\": SVC(probability=True),\n",
    "        }\n",
    "model.run(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['lm']\n",
    "y_raw = data['filtered_tags']\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y_raw)\n",
    "tag_distribution = y.sum(axis=0)\n",
    "constant_tags = tag_distribution == len(y)\n",
    "y = y[:, ~constant_tags]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = FeatureExtractor().transform(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train, y_train, X_test, y_test, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "            \"SGD Classifier\": CalibratedClassifierCV(SGDClassifier(random_state=42, n_jobs=10), method='sigmoid', cv=5),\n",
    "            \"MultinomialNB\": MultinomialNB(),\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=10),\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42, n_jobs=10),\n",
    "            #\"SVM\": SVC(probability=True),\n",
    "        }\n",
    "model.run(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".oc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
